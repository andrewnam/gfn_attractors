{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass, asdict\n",
    "import itertools\n",
    "import string\n",
    "from PIL import Image, ImageShow\n",
    "import matplotlib.pyplot as plt\n",
    "from plotnine import *\n",
    "from plotnine_prism import *\n",
    "from pathlib import Path\n",
    "import io\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import lightning.pytorch as pl\n",
    "import einops\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb\n",
    "import git\n",
    "\n",
    "from gfn_attractors.data.mixture_of_gaussians import GridOfGaussiansDataModule\n",
    "from gfn_attractors.models.helpers import MLP, PositionalEncoding, SafeEmbedding\n",
    "from gfn_attractors.models.dynamics import MLPMeanBoundedDynamics\n",
    "from gfn_attractors.models.discretizer import DiscretizeModule, Discretizer, MLPDiscretizer\n",
    "from gfn_attractors.models.attractor import RNNAttractorModel, RecurrentMLPAttractorModel\n",
    "from gfn_attractors.misc import Config\n",
    "from gfn_attractors.misc import torch_utils as tu, image_utils as iu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_name = 'gaussians_gfn'\n",
    "device = 0\n",
    "seed = 0\n",
    "\n",
    "repo = git.Repo(search_parent_directories=True)\n",
    "repo_root = Path(repo.git_dir).parent.expanduser()\n",
    "checkpoint_dir = repo_root / 'checkpoints' / 'infocog'\n",
    "checkpoint_dir.mkdir(exist_ok=True, parents=True)\n",
    "figures_dir = repo_root / 'figures' / 'infocog'\n",
    "figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "ImageShow.register(ImageShow.IPythonViewer(), 0)\n",
    "torch.tensor(0., device=device)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_module = GridOfGaussiansDataModule(batch_size=50, n_val_samples=500, components_per_dim=4, return_labels=True)\n",
    "data_module.setup(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rows = torch.cat([data_module.train_data.mixture_id.unsqueeze(-1), data_module.train_data.data], dim=-1).numpy()\n",
    "df = pd.DataFrame(rows, columns=['index', 'x', 'y'])\n",
    "df['index'] = df['index'].astype(int).astype(str)\n",
    "df_means = pd.DataFrame(data_module.train_data.means.numpy(), columns=['x', 'y'])\n",
    "x_labels = {k: i for i, k in enumerate(sorted(set(df_means.x)))}\n",
    "y_labels = {k: i for i, k in enumerate(sorted(set(df_means.y)))}\n",
    "df_means['x_label'] = df_means.x.map(x_labels)\n",
    "df_means['y_label'] = df_means.y.map(y_labels)\n",
    "df_means['label'] = df_means.apply(lambda row: f\"{int(row.x_label)},{int(row.y_label)}\", axis=1)\n",
    "\n",
    "p = (\n",
    "    ggplot(df, aes(x='x', y='y')) \n",
    "    + geom_point(aes(color='index'), alpha=.3, size=5)\n",
    "    + geom_point(data=df_means, color='black', size=5)\n",
    "    + geom_text(data=df_means, mapping=aes(label='label', y='y+.1'), size=24, fontweight='bold')\n",
    "    + labs(x='', y='')\n",
    "    + theme_bw()\n",
    "    + theme(legend_position='none',\n",
    "            axis_line=element_blank(),\n",
    "            axis_ticks=element_blank(),\n",
    "            axis_text=element_blank(),\n",
    "            panel_grid=element_blank(),\n",
    "            panel_background=element_blank(),\n",
    "            plot_margin=0.)\n",
    ")\n",
    "\n",
    "p.save(figures_dir / 'gaussians_data.png', dpi=300, width=8, height=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelConfig(Config):\n",
    "    score_weight: float = 4.0  # Weight of the score loss\n",
    "    use_true_attractors: bool = False  # Use the true attractors instead of learning them\n",
    "\n",
    "    # Dynamics\n",
    "    max_steps: int = 30\n",
    "    max_mean: float = 0.05\n",
    "    attractor_sd: float = 0.04\n",
    "    t_dependent_forward: bool = True\n",
    "    t_dependent_backward: bool = True\n",
    "    x_dependent_forward: bool = True\n",
    "    x_dependent_backward: bool = True\n",
    "\n",
    "    # Discretizer\n",
    "    vocab_size: int = 4\n",
    "    w_length: int = 2\n",
    "\n",
    "    # Architetures\n",
    "    dim_h: int = 256\n",
    "    dim_t: int = 10  # temporal encoding for the g_model (not dynamics)\n",
    "    dim_h_discretizer: int = 256\n",
    "    num_dynamics_layers: int = 3\n",
    "    num_discretizer_layers: int = 2\n",
    "    nhead: int = 4 # if using transformer discretizer\n",
    "    dim_feedforward: int = 256 # if using transformer discretizer\n",
    "    \n",
    "    # Training\n",
    "    lr: float = 1e-3    # GFN learning rate\n",
    "    discretizer_lr: float = 1e-3\n",
    "    lookup_lr: float = 1e-4  # Attractor learning rate\n",
    "    p_explore: float = 0.1  # Applies for both the dynamics and discretizer models\n",
    "\n",
    "    # EM switch\n",
    "    num_e_steps: int = 1\n",
    "    num_m_steps: int = 1\n",
    "    max_e_steps: int = np.inf\n",
    "    start_e_steps: int = 0\n",
    "    e_loss_improvement_threshold: float = 0.0 # if the loss improves by at least this much, keep updating E-step\n",
    "    e_step_loss_rate: float = None # increase loss threshold for e-step by this much every e_step\n",
    "    e_step_loss_window: int = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    Simplest possible model for Gaussians task.\n",
    "    z0 is the input.\n",
    "    Reward is negative distance between attractor and input, so no score model is used.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: ModelConfig, data_module: GridOfGaussiansDataModule):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.data_module = data_module\n",
    "\n",
    "        self.temporal_encoding = PositionalEncoding(config.dim_t) if config.dim_t is not None else None\n",
    "        self.dynamics_model = MLPMeanBoundedDynamics(dim_x=2, dim_z=2, \n",
    "                                                     dim_h=config.dim_h,\n",
    "                                                     num_layers=config.num_dynamics_layers,\n",
    "                                                     max_mean=config.max_mean,\n",
    "                                                     max_sd=1,\n",
    "                                                     t_dependent_forward=config.t_dependent_forward,\n",
    "                                                     t_dependent_backward=config.t_dependent_backward,\n",
    "                                                     x_dependent_forward=config.x_dependent_forward,\n",
    "                                                     x_dependent_backward=config.x_dependent_backward)\n",
    "        \n",
    "        self.discretizer = MLPDiscretizer(vocab_size=config.vocab_size, \n",
    "                                          length=config.w_length,\n",
    "                                          dim_input=2,\n",
    "                                          dim_h=config.dim_h_discretizer,\n",
    "                                          num_layers=config.num_discretizer_layers)\n",
    "        self.attractor_model = RecurrentMLPAttractorModel(vocab_size=config.vocab_size, dim_z=2, dim_h=config.dim_h, \n",
    "                                                          residual=False, num_layers=1)\n",
    "        \n",
    "        self.g_model = MLP(4 + self.config.dim_t, 1, hidden_dim=self.config.dim_h, n_layers=2, nonlinearity=nn.ReLU()) # Flow correction model\n",
    "        self.f_z_model = MLP(4, 1, hidden_dim=self.config.dim_h, n_layers=2, nonlinearity=nn.ReLU()) # Flow for discretizer\n",
    "\n",
    "        self.e_step = True\n",
    "        self.num_mode_updates = 0\n",
    "        self.num_m_steps = 0\n",
    "        self.e_step_loss_goal = np.inf\n",
    "        self.e_step_losses = np.zeros(config.e_step_loss_window)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam([{'params': [*self.dynamics_model.parameters(),\n",
    "                                             *self.attractor_model.parameters(),\n",
    "                                             *self.g_model.parameters()],\n",
    "                                  'lr': self.config.lr},\n",
    "                                 {'params': [*self.discretizer.parameters(), \n",
    "                                             *self.f_z_model.parameters()],\n",
    "                                  'lr': self.config.discretizer_lr}])\n",
    "        \n",
    "    def get_score(self, z0, z_hat):\n",
    "        \"\"\"\n",
    "        z0: (..., dim_z)\n",
    "        z_hat: (..., dim_z)\n",
    "        \"\"\"\n",
    "        return Normal(z_hat, self.config.attractor_sd).log_prob(z0).sum(-1)\n",
    "\n",
    "    def get_log_reward(self, z_traj, z_hat, z0=None):\n",
    "        \"\"\"\n",
    "        z_traj: (batch_size, num_steps, dim_z)\n",
    "        z_hat: (batch_size, num_steps, dim_z)\n",
    "        z0: (batch_size, dim_z)\n",
    "        \"\"\"\n",
    "        if z0 is None:\n",
    "            z0 = z_traj[:,0]\n",
    "        z0 = einops.repeat(z0, 'n z -> n t z', t=z_traj.shape[1])\n",
    "        score = self.get_score(z0, z_hat)\n",
    "        sd_zhat = self.config.attractor_sd\n",
    "        logp_zhat = Normal(z_hat, sd_zhat).log_prob(z_traj).sum(-1)\n",
    "        log_reward = self.config.score_weight * score + logp_zhat\n",
    "        metrics = {\n",
    "            'reward/score': score.mean().item(),\n",
    "            'reward/logp_zhat': logp_zhat.mean().item(),\n",
    "            'reward/total': log_reward.mean().item()\n",
    "        }\n",
    "        return log_reward, metrics\n",
    "\n",
    "    def sample_forward_trajectory(self, x, num_steps=None, p_explore=0.):\n",
    "        \"\"\"\n",
    "        x: (batch_size, 2)\n",
    "        returns: (batch_size, num_steps, dim_z)\n",
    "        \"\"\"\n",
    "        if num_steps is None:\n",
    "            num_steps = self.config.max_steps\n",
    "        return self.dynamics_model.sample_trajectory(x, x, num_steps=num_steps, forward=True, p_explore=p_explore, explore_mean=True)\n",
    "    \n",
    "    def sample_backward_trajectory(self, z, x, num_steps=None, p_explore=0.):\n",
    "        \"\"\"\n",
    "        z: (batch_size, 2)\n",
    "        x: (batch_size, 2)\n",
    "        returns: (batch_size, num_steps, dim_z)\n",
    "        \"\"\"\n",
    "        if num_steps is None:\n",
    "            num_steps = self.config.max_steps\n",
    "        return self.dynamics_model.sample_trajectory(z, x, num_steps=num_steps, forward=False, p_explore=p_explore)\n",
    "\n",
    "    def sample_w(self, z, argmax=False, p_explore=0.):\n",
    "        \"\"\"\n",
    "        z: tensor with shape (batch_size, dim_z) or (batch_size, num_steps, dim_z)\n",
    "        returns:\n",
    "            if z has shape (batch_size, dim_z):\n",
    "                w: (batch_size, max_w_length)\n",
    "                logpw: (batch_size,)\n",
    "            if z has shape (batch_size, num_steps, dim_z):\n",
    "                w: (batch_size, num_steps, max_w_length)\n",
    "                logpw: (batch_size, num_steps)\n",
    "        \"\"\"\n",
    "        if z.ndim == 2:\n",
    "            return self.discretizer.sample(z, argmax=argmax, p_explore=p_explore)\n",
    "\n",
    "        batch_size, num_steps = z.shape[:2]\n",
    "        z = z.flatten(0, 1)\n",
    "        w, logpw = self.discretizer.sample(z, argmax=argmax, p_explore=p_explore)\n",
    "        w = w.view(batch_size, num_steps, -1)\n",
    "        logpw = logpw.view(batch_size, num_steps)\n",
    "        return w, logpw\n",
    "\n",
    "    def get_z_hat(self, w):\n",
    "        \"\"\"\n",
    "        w: (batch_size, max_w_length)\n",
    "        returns: (batch_size, dim_z)\n",
    "        \"\"\"\n",
    "        if self.config.use_true_attractors:\n",
    "            shape = w.shape[:-1]\n",
    "            w = w.view(-1, w.shape[-1])\n",
    "            index = w[:,:-1] - 2\n",
    "            z_hat = self.data_module.train_data.means.to(w.device)[index[:,0] * 4 + index[:,1]]\n",
    "            return z_hat.view(*shape, -1)\n",
    "        return self.attractor_model(w)\n",
    "    \n",
    "    def get_discretizer_loss(self, z_traj, logpw, log_reward):\n",
    "        \"\"\"\n",
    "        z_traj: (batch_size, num_steps, dim_z)\n",
    "        logpw: (batch_size, num_steps)\n",
    "        log_reward: (batch_size, num_steps)\n",
    "        \"\"\"\n",
    "        z0 = einops.repeat(z_traj[:,0], 'n z -> n t z', t=z_traj.shape[1])\n",
    "        f = self.f_z_model(torch.cat([z0, z_traj], dim=-1))\n",
    "        loss = f + logpw - log_reward\n",
    "        loss = loss.pow(2).mean()\n",
    "        metrics = {\n",
    "            'discretizer/loss': loss.item(),\n",
    "            'discretizer/logF': f.mean().item(),\n",
    "            'discretizer/logpw': logpw.mean().item(),\n",
    "            'discretizer/log_reward': log_reward.mean().item(),\n",
    "        }\n",
    "        return loss, metrics\n",
    "    \n",
    "    def get_dynamics_loss(self, z_traj, logpf, logpb, logpw, log_reward):\n",
    "        z0 = einops.repeat(z_traj[:,0], 'n z -> n t z', t=z_traj.shape[1] - 1)\n",
    "        z = torch.cat([z0, z_traj[:,:-1]], dim=-1)\n",
    "        g = self.g_model(self.temporal_encoding(z))\n",
    "        g = F.pad(g, (0, 1))\n",
    "\n",
    "        loss = g[:,1:] - g[:,:-1]\n",
    "        loss += -logpw[:,1:] + logpw[:,:-1]\n",
    "        loss += log_reward[:,1:] - log_reward[:,:-1]\n",
    "        loss += logpb - logpf\n",
    "        loss = loss.pow(2).mean()\n",
    "\n",
    "        metrics = {\n",
    "            'dynamics/loss': loss.item(),\n",
    "            'dynamics/logpf': logpf.mean().item(),\n",
    "            'dynamics/logpb': logpb.mean().item(),\n",
    "            'dynamics/logpw': logpw.mean().item(),\n",
    "            'dynamics/log_reward': log_reward.mean().item(),\n",
    "            'dynamics/g': g.mean().item(),\n",
    "        }\n",
    "        return loss, metrics\n",
    "\n",
    "    def get_gfn_loss(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, 2)\n",
    "        \"\"\"\n",
    "        z_traj = self.sample_forward_trajectory(x, p_explore=self.config.p_explore)\n",
    "        w, logpw = self.sample_w(z_traj, mode=self.config.w_traj_mode, p_explore=self.config.p_explore)       \n",
    "        with torch.no_grad():\n",
    "            z_hat = self.get_z_hat(w)\n",
    "\n",
    "        logpf_traj, logpb_traj, mu_f, sd_f, mu_b, sd_b = self.dynamics_model.log_prob(z_traj, x, return_params=True)  \n",
    "        with torch.no_grad():\n",
    "            log_reward, metrics = self.get_log_reward(z_traj, z_hat)\n",
    "        dynamics_loss, dynamics_metrics = self.get_dynamics_loss(z_traj, logpf_traj, logpb_traj, logpw.detach(), log_reward)\n",
    "        discretizer_loss, discretizer_metrics = self.get_discretizer_loss(z_traj, logpw, log_reward)\n",
    "\n",
    "        loss = dynamics_loss + discretizer_loss\n",
    "        metrics.update(dynamics_metrics)\n",
    "        metrics.update(discretizer_metrics)\n",
    "\n",
    "        metrics['dynamics/mu_f'] = mu_f.norm(-1).mean().item()\n",
    "        metrics['dynamics/sd_f'] = sd_f.norm(-1).mean().item()\n",
    "        metrics['dynamics/mu_b'] = mu_b.norm(-1).mean().item()\n",
    "        metrics['dynamics/sd_b'] = sd_b.norm(-1).mean().item()\n",
    "        return loss, metrics\n",
    "\n",
    "    def get_attractor_loss(self, x):\n",
    "        with torch.no_grad():\n",
    "            z_traj = self.sample_forward_trajectory(x)\n",
    "            w, logpw = self.sample_w(z_traj[:,-1], argmax=True)\n",
    "        z_hat = self.get_z_hat(w)\n",
    "        p_x_zhat = -self.get_score(x, z_hat).mean()\n",
    "\n",
    "        # regularization\n",
    "        w = self.discretizer.get_all_w(device=x.device)\n",
    "        z_hat = self.get_z_hat(w)\n",
    "        zhat_reg = (z_hat**2).mean()\n",
    "        loss = p_x_zhat + 1e-4 * zhat_reg\n",
    "        \n",
    "        return loss, {'attractor_loss': loss.item(),\n",
    "                      'p_x_zhat': p_x_zhat.item(),\n",
    "                      'zhat_reg': zhat_reg.item()}\n",
    "    \n",
    "    def check_and_exit_e_step(self, loss, record_loss: bool):\n",
    "        \"\"\"\n",
    "        Returns whether or not the model should exit E-step.\n",
    "        \"\"\"\n",
    "        self.num_mode_updates += 1\n",
    "        if record_loss:\n",
    "            self.e_step_losses = np.roll(self.e_step_losses, 1)\n",
    "            self.e_step_losses[0] = loss.item()\n",
    "        avg_loss = self.e_step_losses.mean()\n",
    "\n",
    "        if self.config.num_m_steps <= 0:\n",
    "            return False\n",
    "        elif self.global_step <= self.config.start_e_steps:\n",
    "            return False\n",
    "        elif self.num_mode_updates < self.config.num_e_steps:\n",
    "            return False\n",
    "        elif self.num_mode_updates >= self.config.max_e_steps:\n",
    "            pass\n",
    "        # elif self.config.e_step_max_loss is not None and avg_loss > self.config.e_step_max_loss:\n",
    "        #     return False\n",
    "        elif self.config.e_step_loss_rate is not None and avg_loss > self.e_step_loss_goal:\n",
    "            self.e_step_loss_goal = self.e_step_loss_goal * self.config.e_step_loss_rate\n",
    "            return False\n",
    "        elif self.config.e_loss_improvement_threshold > 0:\n",
    "            avg_loss_1 = self.e_step_losses[:len(self.e_step_losses)//2].mean()\n",
    "            avg_loss_2 = self.e_step_losses[len(self.e_step_losses)//2:].mean()\n",
    "            if 1 - (avg_loss_2 / avg_loss_1) < self.config.e_loss_improvement_threshold:\n",
    "                return False\n",
    "\n",
    "        self.num_mode_updates = 0\n",
    "        self.e_step = False\n",
    "        self.e_step_loss_goal = avg_loss.item()\n",
    "        self.e_step_losses = np.zeros(self.config.e_step_loss_window)\n",
    "        return True\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        x = batch['data']\n",
    "\n",
    "        if self.e_step or self.config.use_true_attractors: # E-step\n",
    "            loss, metrics = self.get_gfn_loss(x)\n",
    "            self.check_and_exit_e_step(loss, True)\n",
    "            metrics['training/e_step_loss'] = loss.item()\n",
    "            \n",
    "        else: # M-step\n",
    "            loss, metrics = self.get_attractor_loss(x)\n",
    "            self.num_mode_updates += 1\n",
    "            self.num_m_steps += 1\n",
    "            if self.num_mode_updates >= self.config.num_m_steps:\n",
    "                self.num_mode_updates = 0\n",
    "                self.e_step = True\n",
    "            metrics['training/m_step_loss'] = loss.item()\n",
    "\n",
    "        metrics['training/num_m_steps'] = self.num_m_steps\n",
    "        metrics['training/e_step_loss_goal'] = self.e_step_loss_goal\n",
    "        self.log_metrics(**metrics)\n",
    "\n",
    "        # debugging\n",
    "        self._last_x = x\n",
    "        self._last_metrics = metrics\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        if isinstance(self.logger, WandbLogger) and batch_idx == 0:\n",
    "            x = data_module.val_data.data.to(self.device)\n",
    "            z_traj = self.sample_forward_trajectory(x)\n",
    "            self.log_gif('forward', self.plot_steps(z_traj))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def plot_steps(self, z_traj):\n",
    "        w_attractors = self.discretizer.get_all_w(device=z_traj.device)\n",
    "        z_attractors = self.get_z_hat(w_attractors)\n",
    "        batch_size, num_steps = z_traj.shape[:2]\n",
    "        index = pd.MultiIndex.from_product([range(batch_size), range(num_steps)], names=['xid', 'step'])\n",
    "        df_traj = pd.DataFrame(z_traj.cpu().numpy().reshape(-1, z_traj.shape[-1]), \n",
    "                            index=index, columns=[f'z{i}' for i in range(z_traj.shape[-1])]).reset_index()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            w, logpw = self.sample_w(z_traj)\n",
    "        w = tu.to_strings(w.flatten(0, 1), min_value=2, chars=string.ascii_letters)\n",
    "        df_traj['w'] = w\n",
    "\n",
    "        df_attractors = pd.DataFrame(z_attractors.cpu().numpy(), \n",
    "                                    columns=[f'z{i}' for i in range(z_attractors.shape[-1])])\n",
    "        df_attractors['w'] = tu.to_strings(w_attractors, min_value=2, chars=string.ascii_letters)\n",
    "\n",
    "        w_unique = df_traj.w.unique()\n",
    "        colors = {w: c for w, c in zip(w_unique, prism_color_pal('colors')(len(w_unique)))}\n",
    "\n",
    "        def plot_traj_step(step):\n",
    "            p = (ggplot(df_traj[df_traj.step == step], aes(x='z0', y='z1'))\n",
    "            + geom_point(aes(color='w'), alpha=.4, size=1.5)\n",
    "            + geom_text(aes(label='w'), data=df_attractors, size=12, fontweight='bold')\n",
    "            + scale_color_manual(values=colors)\n",
    "            + coord_cartesian(xlim=(-1.5, 1.5), ylim=(-1.5, 1.5))\n",
    "            + labs(title=f\"Step {step}\")\n",
    "            + theme_bw()\n",
    "            + theme(legend_position='none')\n",
    "            )\n",
    "            return p\n",
    "\n",
    "        return [iu.plot_to_image(plot_traj_step(step)) for step in range(num_steps)]\n",
    "\n",
    "    def log_metrics(self, **kwargs):\n",
    "        # prefix = \"validation\" if self.trainer.validating else \"training\"\n",
    "        # d = {f\"{prefix}/{k}\": v for k, v in kwargs.items()}\n",
    "        self.log_dict(kwargs, prog_bar=True)\n",
    "\n",
    "    def log_figure(self, key, p):\n",
    "        img_buf = io.BytesIO()\n",
    "        p.save(img_buf, format='png', verbose = False)\n",
    "        im = Image.open(img_buf).copy()\n",
    "        plt.close()\n",
    "        img_buf.close()\n",
    "        self.logger.log_image(key=key, images=[im], caption=[f'{key} ({self.global_step})'], commit=True)\n",
    "\n",
    "    def log_gif(self, key, images):\n",
    "        imarrays = np.array([np.transpose(np.array(im), (2, 0, 1)) for im in images])\n",
    "        wandb.log({key: wandb.Video(imarrays, fps=1, format='gif', caption=f\"{key} ({self.global_step})\")}, commit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = ModelConfig(score_weight=2,\n",
    "                     use_true_attractors=False,\n",
    "                     brownian_bridge=False, \n",
    "                     dim_h=256,\n",
    "                     dim_h_discretizer=256,\n",
    "                     dim_t=10,\n",
    "                     max_steps=20,\n",
    "                     t_dependent_forward=False,\n",
    "                     max_mean=.05,\n",
    "                     max_sd=1,\n",
    "                     fixed_sd=None,\n",
    "                     w_traj_mode='all',\n",
    "                     num_dynamics_layers=3,\n",
    "                     num_discretizer_layers=2,\n",
    "                     lr=1e-4,\n",
    "                     num_e_steps=50,\n",
    "                     num_m_steps=1,\n",
    "                    #  e_step_loss_rate=1.0001,\n",
    "                     e_step_loss_window=50,\n",
    "                     e_loss_improvement_threshold=0.005,\n",
    "                     start_e_steps=1000)\n",
    "model = Model(config, data_module)\n",
    "x = data_module.train_data.data[:250].cpu()\n",
    "with torch.no_grad():\n",
    "    loss, metrics = model.get_attractor_loss(x)\n",
    "    loss, metrics = model.get_gfn_loss(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.lr = 1e-5\n",
    "# config.discretizer_lr = 1e-4\n",
    "# config.lookup_lr = 1e-4\n",
    "# num_e_steps = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_epochs = 5000\n",
    "check_val_every_n_epoch = 50\n",
    "wandb.finish()\n",
    "logger = WandbLogger(project='gaussians_gfn',\n",
    "                     name=run_name,\n",
    "                     entity='andrewnam',\n",
    "                     config=asdict(config))\n",
    "trainer = pl.Trainer(max_epochs=max_epochs, \n",
    "                     devices=[device], \n",
    "                     check_val_every_n_epoch=check_val_every_n_epoch, \n",
    "                     logger=logger, \n",
    "                     log_every_n_steps=31,\n",
    "                     gradient_clip_val=1.0,\n",
    "                     enable_progress_bar=True)\n",
    "trainer.fit(model, train_dataloaders=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.cpu().state_dict(), checkpoint_dir / 'gfn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
